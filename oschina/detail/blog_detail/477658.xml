<?xml version="1.0" encoding="UTF-8"?><oschina>
	<blog>
								<id>477658</id>
		<title><![CDATA[linux下播放器的设计和开发]]></title>
		<url><![CDATA[http://my.oschina.net/u/2408025/blog/477658]]></url>
		<where><![CDATA[工作日志]]></where>
		<commentCount>1</commentCount>
		<body><![CDATA[<style type='text/css'>pre {white-space:pre-wrap;word-wrap:break-word;}</style><p>本文根据DawnLightPlayer的开发经验写成。DawnLithtPlayer是今天3月份开始,和maddrone一起在业余时间开发的一个跨平台，多线程的播放器,主要是在Linux下面开发的,文中所用示例代码均截自其中。<br>DawnLightPlayer目前可以运行在Linux和Windows系统上，并使用VC和Python开发了GUI，支持大部分的音视频文件格式和网络流，另外新增对CMMB协议的支持,不支持 RMVB, SWF 等尚未公开协议的视频文件格式。<br><br>目录:<br>一. 播放器的流程<br>&nbsp;&nbsp; 1. 输入<br>&nbsp;&nbsp; 2. 解码<br>&nbsp;&nbsp; 3. 输出<br>二. 播放器的实现<br>&nbsp;&nbsp; 1. 输入实现<br>&nbsp;&nbsp; 2. 解码线程实现<br>&nbsp;&nbsp; 3. 输出线程实现<br>三. 视频输出库<br>&nbsp;&nbsp; 1. SDL (多平台,支持硬件缩放)<br>&nbsp;&nbsp; 2. DirectX DirectDraw (win32平台,支持硬件缩放)<br>&nbsp;&nbsp; 3. OpenGL (多平台,支持硬件缩放)<br>&nbsp;&nbsp; 4. X11 (Linux/Unix)<br>&nbsp;&nbsp; 5. FrameBuffer (Linux, 无硬件缩放)<br>四. 音频输出<br>&nbsp;&nbsp; 1. OSS (Open Sound System for Linux)<br>&nbsp;&nbsp; 2. ALSA (Advanced Linux Sound Architecture)<br>&nbsp;&nbsp; 3. DirectSound (WIN32)<br>五. 音视频同步<br>&nbsp;&nbsp; 1. 以音频为基准同步视频<br>&nbsp;&nbsp; 2. 以视频为基准同步音频<br>&nbsp;&nbsp; 3. 同步于一个外部时钟<br>六. 截图<br>&nbsp;&nbsp; 1. 使用jpeglib保存成jpeg文件<br>&nbsp;&nbsp; 2. 使用libpng保存成png文件<br>七. YUV RGB 软件转换<br>八. 软件缩放<br><br><br><br>一. 播放器的流程<br><br>1. 输入 : 从文件或网络等读取原数据，如 x.avi, x.mov, rtsp://xxx, 对原数据进行解析，比如文件，首先要分析文件格式，从文件中取得音视频编码参数，视频时间长度等信息，然后要从其中取出音频编码数据和视频编码数据送到解 码部分，这里暂称这种编码源数据块为 packet。<br><br>2. 解码 : 初始化时，利用输入端从源数据中取得的信息调用不同的解码库初始化；然后接收输入端传送来的音视频编码数据，分别进行音频解码和视频解码，视频解码出来的 数据一般是 YUV 或 RGB 数据，这里暂称为 picture, 音频解码出来的数据是采样数据，是声卡可以播放的数据，这里暂称为 sample。 解码所得的数据接下来送到输出部分。<br><br>3. 输出 ： 接收解码部分送来的 picture 和 sample 并显示。 视频显示一般使用某个图形库，如 SDL, Xlib, DirectDraw, OpengGL, FrameBuffer等, 音频输出是把 sample 写入系统的音频驱动，由音频驱动送入声卡播放, 可用的音频输出有 ALSA, OSS, SDL, DirectSound, WaveOut等。<br><br>二. 播放器的实现<br><br>推荐实现方案<br>一个audio_packet队列，一个video_packet队列,一个picture队列，一个sample队列<br>一个input线程，两个decode线程，两个output线程,一个UI控制线程<br><br>1. 输入实现<br>对 文件的解析，首先要了解文件的格式，文件格式一般称为文件容器。公开的文件格式，按格式协议读取分析就可以了，但像RMVB,SWF这种目前还不公开格式 的文件，就不好办，也是目前一般播放器的困难。一般的文件格式的解析libavformat库已经做了，只要使用它就行，下面给出示例代码段:<br><br>初始化：<br>static int avin_file_init(void)<br>{<br>&nbsp;&nbsp;&nbsp; AVFormatParameters params, *ap = ¶ms;<br>&nbsp;&nbsp;&nbsp; err = av_open_input_file( &amp;fmtctx, input_filename, NULL, 0, ap );<br>&nbsp;&nbsp;&nbsp; if ( err &lt; 0 )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; av_log(NULL, AV_LOG_ERROR, "%d: init input from file error\n", __LINE__);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print_error( input_filename, err );<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<br>&nbsp;&nbsp;&nbsp; }<br><br>&nbsp;&nbsp;&nbsp; fmtctx-&gt;flags |= AVFMT_FLAG_GENPTS;<br><br>&nbsp;&nbsp;&nbsp; err = av_find_stream_info( fmtctx );<br>&nbsp;&nbsp;&nbsp; if ( err &lt; 0 )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; av_log(NULL, AV_LOG_ERROR, "%d: init input from file error\n", __LINE__);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print_error( input_filename, err );<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<br>&nbsp;&nbsp;&nbsp; }<br><br>&nbsp;&nbsp;&nbsp; if (fmtctx-&gt;pb) fmtctx-&gt;pb-&gt;eof_reached = 0;<br>&nbsp;&nbsp;&nbsp; dump_format( fmtctx, 0, input_filename, 0 );<br><br>&nbsp;&nbsp;&nbsp; ....<br>}<br>读取packet:<br>while( 1 )<br>{<br>&nbsp;&nbsp;&nbsp; AVPacket *pkt = NULL;<br>&nbsp;&nbsp;&nbsp; pkt = av_malloc( sizeof(AVPacket) );<br>&nbsp;&nbsp;&nbsp; ret = av_read_frame(fmtctx, pkt);<br>&nbsp;&nbsp; &nbsp;<br>送出packet到解码部分:<br>&nbsp;&nbsp;&nbsp; 可以memcpy, 或用LinkList结构处理,如:<br>&nbsp;&nbsp;&nbsp; push_to_video_packet_queue(pkt);<br>}<br><br>如果是自己的私有输入，比如移动电视的视频输入,代码如下,部分是伪代码:<br>while( 1 )<br>{<br>&nbsp;&nbsp;&nbsp; your_parse_code();<br>&nbsp;&nbsp;&nbsp; size = your_get_video_data(buf);<br><br>&nbsp;&nbsp;&nbsp; pkt = av_mallocz( sizeof(AVPacket) );<br>&nbsp;&nbsp;&nbsp; x = av_new_packet( pkt, vret);<br>&nbsp;&nbsp;&nbsp; memcpy( pkt-&gt;data, buf, size );<br>&nbsp;&nbsp;&nbsp; pkt-&gt;pts = your_time;<br><br>&nbsp;&nbsp;&nbsp; push_to_video_packet_queue(pkt);<br>}<br><br>2. 解码线程实现<br>解码是个算法大课题，大多只能使用已有的解码库，如libavcodec,下面示例代码:<br>while ( 1 )<br>{<br>&nbsp;&nbsp;&nbsp; AVPicture *picture;<br>&nbsp;&nbsp;&nbsp; AVPacket *pkt = pop_from_video_packet_queue();<br>&nbsp;&nbsp;&nbsp; AVFrame *frame = avcodec_alloc_frame();<br>&nbsp;&nbsp;&nbsp; avcodec_decode_video(video_ctxp, frame, &amp;got_picture, pkt-&gt;data, pkt-&gt;size);<br>&nbsp;&nbsp;&nbsp; if ( got_picture )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; convert_frame_to_picture( picture, frame );<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; picture-&gt;pts = pkt-&gt;pts;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; push_to_picture_queue( picture );<br>&nbsp;&nbsp;&nbsp; }<br>}<br>音频雷同<br><br>3. 输出线程实现<br><br>视 频输出要控制FPS，比如25帧每秒的视频，那么每一帧的显示时间要是1/25秒，但把一帧RGB数据写入显存用不了1/25秒的时间，那么就要控制，不 能让25帧的数据在0.1或0.2秒的时间内就显示完了，最简单的实现是在每显示一帧数据后，sleep( 1/fps - 显示用去的时间 )。<br><br>音 视频同步这个重要的工作也要在输出线程里完成。以音频为基准同步视频，以视频为基准同步音频，或与一个外部时钟同步，都是可行的方法，但以音频为基准同步 视频是最简单也最有效的方法。音频驱动只要设置好sample rate, sample size 和 channels 后， write 数据就会以此恒定的速度播放， 如果驱动的输出 buffer 满，则 write 就可以等待。<br><br>视频:<br>while( 1 )<br>{<br>&nbsp;&nbsp;&nbsp; picture = pop_from_picture_queue();<br>&nbsp;&nbsp;&nbsp; picture_shot( picture ); /* 截图 */<br>&nbsp;&nbsp;&nbsp; vo-&gt;display( picture );<br>&nbsp;&nbsp;&nbsp; video_pts = picture-&gt;pts;<br>&nbsp;&nbsp;&nbsp; sync_with_audio(); /* 同步 */<br>&nbsp;&nbsp;&nbsp; control_fps(); /* FPS */<br>}<br>音频：<br>while( 1 )<br>{<br>&nbsp;&nbsp;&nbsp; sample = pop_from_sample_queue();<br>&nbsp;&nbsp;&nbsp; ao-&gt;play( sample );<br>&nbsp;&nbsp;&nbsp; now_pts = sample-&gt;pts;<br>}<br><br>三. 视频输出库<br><br>1. SDL (多平台,支持硬件缩放)<br><br>SDL(Simple DirectMedia Layer) is a cross-platform multimedia library designed to provide low level access to audio, keyboard, mouse, joystick, 3D hardware via OpenGL, and 2D video framebuffer.<br><br>其实SDL就是一个中间件，它封装了下层的OpenGL, FrameBuffer, X11, DirectX等给上层提供一个统一的API接口，使用SDL的优点是我们不必再为X11或DirectX分别做个视频输出程序了。<br><br>SDL可以直接显示YUV数据和RGB数据,一般解码得到的picture都是YUV420P格式的,不用做YUV2RGB的转换就可以直接显示,主要代码如下:<br><br>static int vo_sdl_init(void)<br>{<br>&nbsp;&nbsp;&nbsp; ....<br>&nbsp;&nbsp;&nbsp; screen = SDL_SetVideoMode(ww, wh, 0, flags);<br>&nbsp;&nbsp;&nbsp; overlay = SDL_CreateYUVOverlay(dw, dh, SDL_YV12_OVERLAY, screen);<br>&nbsp;&nbsp; ....<br>}<br><br>static void vo_sdl_display(AVPicture *pict)<br>{<br>&nbsp;&nbsp;&nbsp; SDL_Rect rect;<br>&nbsp;&nbsp;&nbsp; AVPicture p;<br><br>&nbsp;&nbsp;&nbsp; SDL_LockYUVOverlay(overlay);<br>&nbsp;&nbsp;&nbsp; p.data[0] = overlay-&gt;pixels[0];<br>&nbsp;&nbsp;&nbsp; p.data[1] = overlay-&gt;pixels[2];<br>&nbsp;&nbsp;&nbsp; p.data[2] = overlay-&gt;pixels[1];<br>&nbsp;&nbsp;&nbsp; p.linesize[0] = overlay-&gt;pitches[0];<br>&nbsp;&nbsp;&nbsp; p.linesize[1] = overlay-&gt;pitches[2];<br>&nbsp;&nbsp;&nbsp; p.linesize[2] = overlay-&gt;pitches[1];<br>&nbsp;&nbsp;&nbsp; vo_sdl_sws( &amp;p, pict ); /* only do memcpy */<br>&nbsp;&nbsp;&nbsp; SDL_UnlockYUVOverlay(overlay);<br><br>&nbsp;&nbsp;&nbsp; rect.x = dx;<br>&nbsp;&nbsp;&nbsp; rect.y = dy;<br>&nbsp;&nbsp;&nbsp; rect.w = dw;<br>&nbsp;&nbsp;&nbsp; rect.h = dh;<br>&nbsp;&nbsp;&nbsp; SDL_DisplayYUVOverlay(overlay, &amp;rect);<br>}<br><br>2. DirectX DirectDraw (win32平台,支持硬件缩放)<br><br>DirectX是window上使用较多的一种输出,也支持直接YUV或RGB显示，示例代码:<br><br>static int vo_dx_init(void)<br>{<br>&nbsp;&nbsp;&nbsp; DxCreateWindow();<br>&nbsp;&nbsp;&nbsp; DxInitDirectDraw();<br>&nbsp;&nbsp;&nbsp; DxCreatePrimarySurface();<br>&nbsp;&nbsp;&nbsp; DxCreateOverlay();<br>&nbsp;&nbsp;&nbsp; DetectImgFormat();<br>}<br><br>static void vo_dx_display(AVPicture *pic)<br>{<br>&nbsp;&nbsp;&nbsp; vfmt2rgb(my_pic, pic);<br>&nbsp;&nbsp;&nbsp; memcpy( g_image, my_pic-&gt;data[0], my_pic-&gt;linesize[0] * height );<br>&nbsp;&nbsp;&nbsp; flip_page();<br>}<br><br>3. OpenGL (多平台,支持硬件缩放)<br><br>OpenGL是3D游戏库，跨平台，效率高，支持大多数的显示加速，显示2D RGB数据只要使用glDrawPixels函数就足够了,同时禁用一些OpenGL管线操作效率更高,如:<br><br>&nbsp;&nbsp;&nbsp; glDisable( GL_SCISSOR_TEST );<br>&nbsp;&nbsp;&nbsp; glDisable( GL_ALPHA_TEST );<br>&nbsp;&nbsp;&nbsp; glDisable( GL_DEPTH_TEST );<br>&nbsp;&nbsp;&nbsp; glDisable( GL_DITHER );<br><br>4. X11 (Linux/Unix)<br><br>X11 是Unix/Linux系统平台上的基本图形界面库，像普通的GTK，QT等主要都是建立在X11的基础之上。但X11的API接口太多，复杂，很不利于 开发，基本的GUI程序一般都会使用GTK，QT等，不会直接调用X11的API，这里只是为了效率。MPlyaer的libvo里有X11的完整使用代 码，包括全屏等功能。<br><br>static void vo_x11_display(AVPicture* pic)<br>{<br>&nbsp;&nbsp;&nbsp; vfmt2rgb( my_pic, pic );<br>&nbsp;&nbsp;&nbsp; Ximg-&gt;data = my_pic-&gt;data[0];<br>&nbsp;&nbsp;&nbsp; XPutImage(Xdisplay, Xvowin, Xvogc, Ximg,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0, 0, 0, 0, dw, dh);<br>&nbsp;&nbsp;&nbsp; XSync(Xdisplay, False);<br>&nbsp;&nbsp;&nbsp; XSync(Xdisplay, False);<br>}<br><br>5. FrameBuffer (Linux, 无硬件缩放)<br><br>FrameBuffer是Linux内核的一部分，提供一个到显存的存取地址的map,但没有任何加速使用。<br><br>static void vo_fb_display(AVPicture *pic)<br>{<br>&nbsp;&nbsp;&nbsp; int i;<br>&nbsp;&nbsp;&nbsp; uint8_t *src, *dst = fbctxp-&gt;mem;<br><br>&nbsp;&nbsp;&nbsp; vfmt2rgb( my_pic, pic );<br>&nbsp;&nbsp;&nbsp; src = my_pic-&gt;data[0];<br><br>&nbsp;&nbsp;&nbsp; for ( i = 0; i &lt; fbctxp-&gt;dh; i++ )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; memcpy( dst, src, fbctxp-&gt;dw * (fbctxp-&gt;varinfo.bits_per_pixel / 8) );<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; dst += fbctxp-&gt;fixinfo.line_length;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; src += my_pic-&gt;linesize[0];<br>&nbsp;&nbsp;&nbsp; }<br>}<br><br>四. 音频输出<br><br>1. OSS (Open Sound System for Linux)<br><br>OSS是Linux下面最简单的音频输出了，直接write就可以。<br><br>static int ao_oss_init(void)<br>{<br>&nbsp;&nbsp;&nbsp; int i;<br>&nbsp;&nbsp;&nbsp; dsp = open(dsp_dev, O_WRONLY);<br>&nbsp;&nbsp;&nbsp; if ( dsp &lt; 0 )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; av_log(NULL, AV_LOG_ERROR, "open oss: %s\n", strerror(errno));<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; i = sample_rate;<br>&nbsp;&nbsp;&nbsp; ioctl (dsp, SNDCTL_DSP_SPEED, &amp;i);<br>&nbsp;&nbsp;&nbsp; i = format2oss(sample_fmt);<br>&nbsp;&nbsp;&nbsp; ioctl(dsp, SNDCTL_DSP_SETFMT, &amp;i);<br>&nbsp;&nbsp;&nbsp; i = channels;<br>&nbsp;&nbsp;&nbsp; if ( i &gt; 2 ) i = 2;<br>&nbsp;&nbsp;&nbsp; ioctl(dsp, SNDCTL_DSP_CHANNELS, &amp;i);<br><br>&nbsp;&nbsp;&nbsp; return 0;<br>}<br><br>static void ao_oss_play(AVSample *s)<br>{<br>&nbsp;&nbsp;&nbsp; write(dsp, s-&gt;data, s-&gt;size);<br>}<br><br>2. ALSA (Advanced Linux Sound Architecture)<br><br>ALSA做的比较失败，长长的函数名。<br><br>static void ao_alsa_play(AVSample *s)<br>{<br>&nbsp;&nbsp;&nbsp; int num_frames = s-&gt;size / bytes_per_sample;<br>&nbsp;&nbsp;&nbsp; snd_pcm_sframes_t res = 0;<br>&nbsp;&nbsp;&nbsp; uint8_t *data = s-&gt;data;<br><br>&nbsp;&nbsp;&nbsp; if (!alsa_handle)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return ;<br><br>&nbsp;&nbsp;&nbsp; if (num_frames == 0)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return ;<br><br>rewrite:<br>&nbsp;&nbsp;&nbsp; res = snd_pcm_writei(alsa_handle, data, num_frames);<br>&nbsp;&nbsp;&nbsp; if ( res == -EINTR )<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; goto rewrite;<br>&nbsp;&nbsp;&nbsp; if ( res &lt; 0 )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; snd_pcm_prepare(alsa_handle);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; goto rewrite;<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; if ( res &lt; num_frames )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; data += res * bytes_per_sample;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; num_frames -= res;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; goto rewrite;<br>&nbsp;&nbsp;&nbsp; }<br>}<br><br>3. DirectSound (WIN32)<br><br>MS DirectX的一部分,它的缺点是不如Linux里面的OSS或ALSA那样，在没有sample写入的时候，自动 silent,DirectSound在播放过程中，当没有sample数据送入输出线程时，它总是回放最后0.2或0.5秒的数据。由于只是最近移植 DawnLightPlayer才使用起Windows，不太了解其机制。<br><br>static void dsound_play(AVSample *s)<br>{<br>&nbsp;&nbsp;&nbsp; int wlen, ret, len = s-&gt;size;<br>&nbsp;&nbsp;&nbsp; uint8_t *data = s-&gt;data;<br><br>&nbsp;&nbsp;&nbsp; while ( len &gt; 0 )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; wlen = dsound_getspace();<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if ( wlen &gt; len ) wlen = len;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ret = write_buffer(data, wlen);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; data += ret;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; len -= ret;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; usleep(10*1000);<br>&nbsp;&nbsp;&nbsp; }<br>}<br><br>五. 音视频同步<br><br>1. 以音频为基准同步视频<br><br>视频输出线程中如下处理:<br>&nbsp;&nbsp;&nbsp; start_time = now();<br>&nbsp;&nbsp;&nbsp; ....<br>&nbsp;&nbsp;&nbsp; vo-&gt;display( picture );<br>&nbsp;&nbsp;&nbsp; last_video_pts = picture-&gt;pts;<br>&nbsp;&nbsp;&nbsp; end_time = now();<br>&nbsp;&nbsp;&nbsp; rest_time = end_time - start_time;<br>&nbsp;&nbsp;&nbsp; av_diff = last_audio_pts - last_video_pts;<br>&nbsp;&nbsp;&nbsp; if ( av_diff &gt; 0.2 )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if ( av_diff &lt; 0.5 ) rest_time -= rest_time / 4;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; else rest_time -= rest_time / 2;<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; else if ( av_diff &lt; -0.2)<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if ( av_diff &gt; -0.5 ) rest_time += rest_time / 4;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; else rest_time += rest_time / 2;<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; if ( rest_time &gt; 0 )<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; usleep(rest_time);<br><br>2. 以视频为基准同步音频<br><br><br>3. 同步于一个外部时钟<br><br><br><br>六. 截图<br><br>截图可以在解码线程做，也可以在输出线程做，见前面的输出线程部分。只要在display前把picture保存起来即可。一般加一些编码，如保存成 PNG 或 JPEG 格式。<br><br>1. 使用jpeglib保存成jpeg文件<br><br>static void draw_jpeg(AVPicture *pic)<br>{<br>&nbsp;&nbsp;&nbsp; char fname[128];<br>&nbsp;&nbsp;&nbsp; struct jpeg_compress_struct cinfo;<br>&nbsp;&nbsp;&nbsp; struct jpeg_error_mgr jerr;<br>&nbsp;&nbsp;&nbsp; JSAMPROW row_pointer[1];<br>&nbsp;&nbsp;&nbsp; int row_stride;<br>&nbsp;&nbsp;&nbsp; uint8_t *buffer;<br><br>&nbsp;&nbsp;&nbsp; if ( !po_status )<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return ;<br><br>&nbsp;&nbsp;&nbsp; vfmt2rgb24(my_pic, pic);<br>&nbsp;&nbsp;&nbsp; buffer = my_pic-&gt;data[0];<br><br>#ifdef __MINGW32__<br>&nbsp;&nbsp;&nbsp; sprintf(fname, "%s\\DLPShot-%d.jpg", get_save_path(), framenum++);<br>#else<br>&nbsp;&nbsp;&nbsp; sprintf(fname, "%s/DLPShot-%d.jpg", get_save_path(), framenum++);<br>#endif<br>&nbsp;&nbsp;&nbsp; fp = fopen (fname, "wb");<br>&nbsp;&nbsp;&nbsp; if (fp == NULL)<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; av_log(NULL, AV_LOG_ERROR, "fopen %s error\n", fname);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return;<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; cinfo.err = jpeg_std_error(&amp;jerr);<br>&nbsp;&nbsp;&nbsp; jpeg_create_compress(&amp;cinfo);<br>&nbsp;&nbsp;&nbsp; jpeg_stdio_dest(&amp;cinfo, fp);<br><br>&nbsp;&nbsp;&nbsp; cinfo.image_width = width;<br>&nbsp;&nbsp;&nbsp; cinfo.image_height = height;<br>&nbsp;&nbsp;&nbsp; cinfo.input_components = 3;<br>&nbsp;&nbsp;&nbsp; cinfo.in_color_space = JCS_RGB;<br><br>&nbsp;&nbsp;&nbsp; jpeg_set_defaults(&amp;cinfo);<br>&nbsp;&nbsp;&nbsp; cinfo.write_JFIF_header = TRUE;<br>&nbsp;&nbsp;&nbsp; cinfo.JFIF_major_version = 1;<br>&nbsp;&nbsp;&nbsp; cinfo.JFIF_minor_version = 2;<br>&nbsp;&nbsp;&nbsp; cinfo.density_unit = 1;<br>&nbsp;&nbsp;&nbsp; cinfo.X_density = jpeg_dpi * width / width;<br>&nbsp;&nbsp;&nbsp; cinfo.Y_density = jpeg_dpi * height / height;<br>&nbsp;&nbsp;&nbsp; cinfo.write_Adobe_marker = TRUE;<br><br>&nbsp;&nbsp;&nbsp; jpeg_set_quality(&amp;cinfo, jpeg_quality, jpeg_baseline);<br>&nbsp;&nbsp;&nbsp; cinfo.optimize_coding = jpeg_optimize;<br>&nbsp;&nbsp;&nbsp; cinfo.smoothing_factor = jpeg_smooth;<br>&nbsp;&nbsp;&nbsp; if ( jpeg_progressive_mode )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; jpeg_simple_progression(&amp;cinfo);<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; jpeg_start_compress(&amp;cinfo, TRUE);<br><br>&nbsp;&nbsp;&nbsp; row_stride = width * 3;<br>&nbsp;&nbsp;&nbsp; while (cinfo.next_scanline &lt; height)<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; row_pointer[0] = &amp;buffer[cinfo.next_scanline * row_stride];<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (void)jpeg_write_scanlines(&amp;cinfo, row_pointer, 1);<br>&nbsp;&nbsp;&nbsp; }<br><br>&nbsp;&nbsp;&nbsp; jpeg_finish_compress(&amp;cinfo);<br>&nbsp;&nbsp;&nbsp; fclose(fp);<br>&nbsp;&nbsp;&nbsp; jpeg_destroy_compress(&amp;cinfo);<br><br>&nbsp;&nbsp;&nbsp; return ;<br>}<br><br>2. 使用libpng保存成png文件<br><br>static void draw_png(AVPicture *pic)<br>{<br>&nbsp;&nbsp;&nbsp; int k;<br>&nbsp;&nbsp;&nbsp; png_byte *row_pointers[height]; /* GCC C99 */<br><br>&nbsp;&nbsp;&nbsp; if ( init_png() &lt; 0 )<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; av_log(NULL, AV_LOG_ERROR, "draw_png: init png error\n");<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return ;<br>&nbsp;&nbsp;&nbsp; }<br><br>&nbsp;&nbsp;&nbsp; vfmt2rgb24( my_pic, pic );<br><br>&nbsp;&nbsp;&nbsp; for ( k = 0; k &lt; height; k++ )<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; row_pointers[k] = my_pic-&gt;data[0] + my_pic-&gt;linesize[0] * k;<br><br>&nbsp;&nbsp;&nbsp; png_write_image(png.png_ptr, row_pointers);<br><br>&nbsp;&nbsp;&nbsp; destroy_png();<br>}<br><br><br>七. YUV RGB 转换<br><br>YUV 与RGB的转换和缩放，一般在低端设备上，要有硬件加速来做，否则CPU吃不消。在如今的高端PC上，可以使用软件来做，libswscale库正为此而 来。libswscale针对X86 CPU已经做了优化，如使用 MMX, SSE, 3DNOW 等 CPU 相关的多媒体指令。<br><br>static int vfmt2rgb(AVPicture *dst, AVPicture *src)<br>{<br>&nbsp;&nbsp;&nbsp; static struct SwsContext *img_convert_ctx;<br><br>&nbsp;&nbsp;&nbsp; img_convert_ctx = sws_getCachedContext(img_convert_ctx,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; width, height, src_pic_fmt,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; width, height, my_pic_fmt, SWS_X, NULL, NULL, NULL);<br><br>&nbsp;&nbsp;&nbsp; sws_scale(img_convert_ctx, src-&gt;data, src-&gt;linesize,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0, width, dst-&gt;data, dst-&gt;linesize);<br><br>&nbsp;&nbsp;&nbsp; return 0;<br>}<br><br>比如从 YUV420P 到 RGB24 的转换，只要设置<br><br>src_pic_fmt = PIX_FMT_YUV420P ;<br>my_pic_fmt = PIX_FMT_RGB24 ;<br><br><br>八. 软件缩放<br><br>软件缩放就可以使用上述的 libswscale 库，调用代码基本一样，只是改一下目标picture的width和height,如放大两倍:<br><br>static int zoom_2(AVPicture *dst, AVPicture *src)<br>{<br>&nbsp;&nbsp;&nbsp; static struct SwsContext *img_convert_ctx;<br><br>&nbsp;&nbsp;&nbsp; img_convert_ctx = sws_getCachedContext(img_convert_ctx,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; width, height, src_pic_fmt,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; width*2, height*2, my_pic_fmt, SWS_X, NULL, NULL, NULL);<br><br>&nbsp;&nbsp;&nbsp; sws_scale(img_convert_ctx, src-&gt;data, src-&gt;linesize,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0, width*2, dst-&gt;data, dst-&gt;linesize);<br><br>&nbsp;&nbsp;&nbsp; return 0;<br>}</p>]]></body>
		<author><![CDATA[学习环境]]></author>
		<authorid>2408025</authorid>
		<documentType>1</documentType>
        <pubDate>2015-07-12 22:54:21</pubDate>
		<favorite>0</favorite>
			</blog>
</oschina>