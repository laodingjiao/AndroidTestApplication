<?xml version="1.0" encoding="UTF-8"?><oschina>
	<blog>
								<id>473150</id>
		<title><![CDATA[Flume入门]]></title>
		<url><![CDATA[http://my.oschina.net/u/2377453/blog/473150]]></url>
		<where><![CDATA[Linux]]></where>
		<commentCount>2</commentCount>
		<body><![CDATA[<style type='text/css'>pre {white-space:pre-wrap;word-wrap:break-word;}</style><h1>1、Flume是什么？</h1> 
<p><br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="FONT-SIZE: 16px">○ Flume是由cloudera开发的实时日志收集系统<br></span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="FONT-SIZE: 16px">○ 核心概念是由一个叫做Agent(代理节点)的java进程运行在日志收集节点<br></span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="FONT-SIZE: 16px">○ Flume在0.94.0版本以前(包含0.94.0版本)称为Cloudera Flume OG,由于0.94.0版本以前存在各种缺陷,因此不得不重新设计Flume并更名为Apache Flume NG(1.0.0开始)<br></span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="FONT-SIZE: 16px">○ Flume NG VS Flume OG<br></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 目前版本都是Flume NG(1.0.0版本之后)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><span style="FONT-SIZE: 14px">架构方面：<br></span></strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;□ Flume OG有三种角色的节点：代理节点agent、收集节点collector、主节点master<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;□ agent负责从各个数据源收集日志数据、将收集到的数据集中到collector,再由collector节点汇总存入到HDFS.而master负责管理agent\collector的活动<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;□ agent、collector都称为node,node的角色根据配置的不同分为逻辑节点和物理节点,对于逻辑节点的区分、配置、使用非常复杂.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;□ agent、collector由source、sink组成,表示当前节点的数据从source传送到sink</p> 
<hr> 
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上相对于Flume NG来说:</p> 
<hr> 
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;□ Flume NG只有一种角色节点：代理节点agent<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;□ 没有collector、master节点,这是最核心的变化.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; □ 去除逻辑节点和物理节点的概念和内容<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; □ agent节点的组成发生变化,由source 、sink、channel三个组件组成<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><span style="FONT-SIZE: 14px">Zookeeper方面：<br></span></strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;□ Flume OG的稳定性依赖zookeeper,它需要zookeeper对其多类节点的工作进行管理,虽然OG可以使用内存的方式对各类节点进行管理,但需要用户忍受机器出现故障时信息丢失的出现.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;□ Flume NG的节点角色数量由原来的3个缩减为1个,不存在多类角色的问题,所以不再需要zookeeper对各类节点协调的作用,由此脱离了对zookeeper的依赖.</p> 
<p><br></p> 
<h1>2、Flume的三个组件</h1> 
<p><br>&nbsp;&nbsp;&nbsp;&nbsp;一个Agent进程包含了三个组件：Source组件、Channel组件、Sink组件，Source组件负责收集日志文件并发送给Channel组件,Channel组件形成一个管道,再由Sink组件读取Channel组件中的日志文件并发送给其他目标或者文件系统</p> 
<p><img src="http://192.168.79.254:8080/oschina/images/uploads/space/2015/0702/025710_F1cV_2377453.png">&nbsp;&nbsp;</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Source组件：</strong>专门收集日志文件，可以处理各种类型的日志数据，如：Avro、Thrift、Exec、JMS、Spooling Directory、Twitter、Kafka、NetCat、Sequence Generator、Syslog、HTTP、Stress、Legacy、Custom(自定义格式)、Scribe<br>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Channel组件：</strong>专门用于存放临时文件，存储的位置可以是Memory、JDBC、Kafka、File、Spillable Memory、Pseudo Transaction、Custom(自定义)<br>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Sink组件：</strong>专门用于发送存放在Channel组件中的数据，发送的目标包括：HDFS、Hive、Logger、Thrift、IRC、File Roll、Null、HBase、MorphlineSolr、ElasticSearch、Kite Dataset、Kafka、Custom(自定义)<br>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Note:<br></strong>&nbsp;&nbsp;○ 具体各种使用请参官方文档：<a href="http://flume.apache.org/FlumeUserGuide.html#flume-sink-processors" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#flume-sink-processors</a><br>&nbsp;&nbsp;○ Channel中的数据只有在Sink组件发送成功后才会被删除<br>&nbsp;&nbsp;○ 在整个数据的传输过程中流动的是event,event可以理解为是flume中数据传输的基本单位,event表现为一条条的数据,其事务保证是event级别.<br>&nbsp;&nbsp;○ flume支持多级flume的agent,支持扇入(fan-in)\扇出(fan-out)</p> 
<p><br><img src="http://192.168.79.254:8080/oschina/images/uploads/space/2015/0702/025857_e36c_2377453.png"></p>
<p>&nbsp;</p> 
<p><strong>Note:</strong></p> 
<p>&nbsp;&nbsp;&nbsp;&nbsp;○ Sink支持发送多个目标</p> 
<p><br></p> 
<h1>3、Flume的安装与配置</h1> 
<p><br>&nbsp;○ 下载<br>&nbsp;&nbsp;&nbsp;&nbsp;apache-flume-1.6.0-bin.tar.gz<br>&nbsp;&nbsp;&nbsp;&nbsp;JDK版本：1.6+<br>&nbsp;○ 解压FLUME_HOME</p> 
<pre class="brush:shell;toolbar: true; auto-links: false;">tar&nbsp;-zxvf&nbsp;apache-flume-1.6.0-bin.tar.gz</pre> 
<p>&nbsp;○ 安装JDK、配置JAVA_HOME、FLUME_HOME.</p> 
<pre class="brush:shell;toolbar: true; auto-links: false;">vi&nbsp;/etc/profile
export&nbsp;FLUME_HOME=/home/app/flume
export&nbsp;PATH=.:$FLUME_HOME/bin</pre> 
<p>&nbsp;○ 一个简单的例子,监控/home/data/logs目录,一旦有发现文件立即上传到hdfs中<br>&nbsp;&nbsp;□ 首先编写一个配置文件,文件名为:example.conf</p> 
<pre class="brush:java;toolbar: true; auto-links: false;">#agent1表示代理名称
&nbsp;&nbsp;agent1.sources=source1
&nbsp;&nbsp;agent1.sinks=sink1
&nbsp;&nbsp;agent1.channels=channel1&nbsp;&nbsp;#Spooling&nbsp;Directory是监控指定文件夹中新文件的变化，一旦新文件出现，就解析该文件内容，然后写入到channle。写入完成后，标记该文件已完成或者删除该文件。
&nbsp;&nbsp;#配置source1
&nbsp;&nbsp;agent1.sources.source1.type=spooldir
&nbsp;&nbsp;#指定监控的目录
&nbsp;&nbsp;agent1.sources.source1.spoolDir=/home/data/logs
&nbsp;&nbsp;agent1.sources.source1.channels=channel1
&nbsp;&nbsp;agent1.sources.source1.fileHeader&nbsp;=&nbsp;false
&nbsp;&nbsp;agent1.sources.source1.interceptors&nbsp;=&nbsp;i1
&nbsp;&nbsp;agent1.sources.source1.interceptors.i1.type&nbsp;=&nbsp;timestamp
&nbsp;&nbsp;#配置sink1
&nbsp;&nbsp;agent1.sinks.sink1.type=hdfs
&nbsp;&nbsp;agent1.sinks.sink1.hdfs.path=hdfs://master:9000/flume/data
&nbsp;&nbsp;agent1.sinks.sink1.hdfs.fileType=DataStream
&nbsp;&nbsp;agent1.sinks.sink1.hdfs.writeFormat=TEXT
&nbsp;&nbsp;agent1.sinks.sink1.hdfs.rollInterval=1
&nbsp;&nbsp;agent1.sinks.sink1.channel=channel1
&nbsp;&nbsp;agent1.sinks.sink1.hdfs.filePrefix=%Y-%m-%d
&nbsp;&nbsp;#配置channel1
&nbsp;&nbsp;agent1.channels.channel1.type=file
&nbsp;&nbsp;#channel数据存放的备份目录
&nbsp;&nbsp;agent1.channels.channel1.checkpointDir=/home/data/channel_data.backup
&nbsp;&nbsp;#channel数据存放目录
&nbsp;&nbsp;agent1.channels.channel1.dataDirs=/home/data/channel_data</pre> 
<p>&nbsp;&nbsp;□ 将example.conf文件放到$FLUME_HOME/conf文件夹下<br>&nbsp;&nbsp;□ 启动agent进程命令：需要指定agent的名字、指定配置目录和配置文件<br>&nbsp;&nbsp;&nbsp; 官方格式：</p> 
<pre class="brush:java;toolbar: true; auto-links: false;">bin/flume-ng&nbsp;agent&nbsp;-n&nbsp;$agent_name&nbsp;-c&nbsp;conf&nbsp;-f&nbsp;conf/flume-conf.properties.template</pre> 
<p>在例子中编写成如下↓↓</p> 
<pre class="brush:java;toolbar: true; auto-links: false;">&nbsp;bin/flume-ng&nbsp;agent&nbsp;-n&nbsp;agent1&nbsp;-c&nbsp;conf&nbsp;-f&nbsp;conf/example.conf&nbsp;-Dflume.root.logger=DEBUG,console
&nbsp;-Dflume.root.logger=DEBUG,console是在控制台打印信息</pre> 
<p>&nbsp;&nbsp;□ 重新打开一个终端，上传一个文件到/home/data/logs<br>&nbsp;&nbsp;□ /home/data/logs中的文件被更名为.COMPLETED,查看HDFS文件存在,配置完毕<br>待续更新...<br></p>]]></body>
		<author><![CDATA[datapro]]></author>
		<authorid>2377453</authorid>
		<documentType>1</documentType>
        <pubDate>2015-07-02 03:03:09</pubDate>
		<favorite>0</favorite>
			</blog>
</oschina>